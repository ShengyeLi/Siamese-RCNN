{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h4Lp8opE6Na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpvUc7cDPSTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget -O backdoor.zip http://jacarini.dinf.usherbrooke.ca/static/dataset/shadow/backdoor.zip\n",
        "# !wget -O pedestrian.zip http://jacarini.dinf.usherbrooke.ca/static/dataset/baseline/pedestrians.zip\n",
        "# !wget -O cubicle.zip http://jacarini.dinf.usherbrooke.ca/static/dataset/shadow/cubicle.zip\n",
        "# !wget -O busStation.zip http://jacarini.dinf.usherbrooke.ca/static/dataset/shadow/busStation.zip\n",
        "# !wget -O peopleinshadow.zip http://jacarini.dinf.usherbrooke.ca/static/dataset/shadow/peopleInShade.zip\n",
        "\n",
        "# !unzip backdoor.zip\n",
        "# !unzip pedestrian.zip\n",
        "# !unzip cubicle.zip\n",
        "# !unzip busStation.zip\n",
        "# !unzip peopleinshadow.zip\n",
        "\n",
        "# !rm backdoor.zip\n",
        "# !rm pedestrian.zip\n",
        "# !rm cubicle.zip\n",
        "# !rm busStation.zip\n",
        "# !rm peopleinshadow.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPnlro9h6rTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = {}\n",
        "aa = lambda x, y: list(range(x, y))\n",
        "files[\"backdoor\"] = {\"background\": [(400, 1358), (1561, 1629), (1995, 2000)],\n",
        "                     \"foreground\": [aa(1404, 1524), \n",
        "                                    aa(1658, 1742), \n",
        "                                    aa(1833, 1870) + aa(1897, 1929)]}\n",
        "files[\"cubicle\"] = {\"background\": [(1416, 1557), (1817, 1951), (6641, 6924), (7181, 7400)],\n",
        "                    \"foreground\": [aa(1172, 1398),\n",
        "                                   aa(1611, 1801),\n",
        "                                   aa(1972, 2174),\n",
        "                                   aa(2308, 2522),\n",
        "                                   aa(6035, 6152),\n",
        "                                   aa(6323, 6453),\n",
        "                                   aa(6500, 6571),\n",
        "                                   aa(6601, 6629),\n",
        "                                   aa(6934, 7121)]}\n",
        "files[\"pedestrians\"] = {\"background\": [(713, 826)], \n",
        "                        \"foreground\": [aa(318, 401),\n",
        "                                       aa(511, 556), \n",
        "                                       aa(602, 694), \n",
        "                                       aa(854, 1035), \n",
        "                                       aa(1056, 1099)]}\n",
        "files[\"peopleInShade\"] = {\"background\":[(250, 284), (371, 434), (509, 573), \n",
        "                                         (808, 825), (989, 1056)], \n",
        "                           \"foreground\":[aa(292, 313), \n",
        "                                         aa(451, 502), \n",
        "                                         aa(589, 796), \n",
        "                                         aa(845, 858)]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcjqMJLf7Hom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import random\n",
        "\n",
        "savepath = \"./dataset/\"\n",
        "readpath = \"./detections/pedestrian detection dataset/\"\n",
        "if not os.path.isdir(savepath):\n",
        "    os.makedirs(savepath)\n",
        "if not os.path.isdir(\"./dataset/gt/\"):\n",
        "    os.makedirs(\"./dataset/gt/\")\n",
        "if not os.path.isdir(\"./dataset/in/\"):\n",
        "    os.makedirs(\"./dataset/in/\")\n",
        "if not os.path.isdir(\"./dataset/bk/\"):\n",
        "    os.makedirs(\"./dataset/bk/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBI-9OB-7KCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def syn(persons, gts, back, overlap, seed):\n",
        "    finalgt = np.zeros_like(gts[0])\n",
        "    finalim = back.copy()\n",
        "    orders = list(range(len(persons)))\n",
        "    random.seed(seed)\n",
        "    random.shuffle(orders)\n",
        "    xywh = []\n",
        "    seedi = seed + 119\n",
        "    seedj = seed + 2843\n",
        "\n",
        "    for i, order in enumerate(orders):\n",
        "        m = 0\n",
        "        foreground = persons[order]\n",
        "        groundtruth = gts[order]\n",
        "            \n",
        "        pixels = np.where(groundtruth[:,:,0] >160)\n",
        "        ymin = np.min(pixels[0])\n",
        "        ymax = np.max(pixels[0])\n",
        "        xmin = np.min(pixels[1])\n",
        "        xmax = np.max(pixels[1])\n",
        "        \n",
        "        newgt = groundtruth[ymin:ymax, xmin:xmax,:]\n",
        "        newgt[newgt < 200] = 0\n",
        "        newgt[newgt > 200] = 1\n",
        "        newim = foreground[ymin:ymax, xmin:xmax,:]\n",
        "        \n",
        "        random.seed(seed + 3)\n",
        "        newsize = random.gauss(0.9, 0.1)\n",
        "        newsize = 1 if newsize > 1 else newsize\n",
        "        newsize = 0.7 if newsize < 0.7 else newsize\n",
        "        newim = cv.resize(newim, None, fx=newsize, fy=newsize)\n",
        "        newgt = cv.resize(newgt, None, fx=newsize, fy=newsize)\n",
        "\n",
        "        random.seed(seed + 175)\n",
        "        if random.uniform(0, 1)>0.5:\n",
        "            newim = newim[:, ::-1, :]\n",
        "            newgt = newgt[:, ::-1, :]\n",
        "        \n",
        "        if overlap and i==1:\n",
        "            while True:\n",
        "                seedi += 1\n",
        "                m += 1\n",
        "                n = 0\n",
        "                if m > 1000:\n",
        "                    return finalim, finalgt\n",
        "                x0, y0, w0, h0 = xywh[0]\n",
        "                top = y0 - h0 * 3 // 2\n",
        "                left = x0 - w0 * 3 // 2\n",
        "                right = x0 + w0 * 3 // 2\n",
        "                bottom = y0 + h0 * 3 // 2\n",
        "                top = 0 if top < 0 else top\n",
        "                left = 0 if left < 0 else left\n",
        "                right = back.shape[1] if right > back.shape[1] else right\n",
        "                bottom = back.shape[0] if bottom > back.shape[0] else bottom\n",
        "                while True:\n",
        "                    n += 1\n",
        "                    if n > 2000:\n",
        "                        return finalim, finalgt\n",
        "                    seedj += 98\n",
        "                    random.seed(seedi + seedj)\n",
        "                    y= random.randint(top, bottom)\n",
        "                    random.seed((seedi + seedj) //32 )\n",
        "                    x = random.randint(left, right)\n",
        "\n",
        "                    if y+newim.shape[0] < back.shape[0] and x+newim.shape[1] < back.shape[1]:\n",
        "                        break\n",
        "                gtt = np.zeros_like(groundtruth)\n",
        "                gtt[y:y+newim.shape[0], x:x+newgt.shape[1]] = newgt\n",
        "                n2and1 = len(np.where((gtt * finalgt) > 0)[0])\n",
        "                n1 = len(np.where(gtt > 0)[0])\n",
        "                n2 = len(np.where(gtt > 0)[0])\n",
        "                if n2and1 < min(n1, n2) * 0.7 and n2and1 > min(n1, n2) * 0.2:\n",
        "                    break\n",
        "        else:\n",
        "            while True:\n",
        "                seedi += 1\n",
        "                m += 1\n",
        "                n = 0\n",
        "                if m > 1000:\n",
        "                    return finalim, finalgt\n",
        "                while True:\n",
        "                    seedj += 1\n",
        "                    n += 1\n",
        "                    if n > 2000:\n",
        "                        return finalim, finalgt\n",
        "                    random.seed(seedi + seedj + 21)\n",
        "                    y = random.randint(0, back.shape[0])\n",
        "                    random.seed(seedi + seedj + 981)\n",
        "                    x = random.randint(0, back.shape[1])\n",
        "                    if y+newim.shape[0] < back.shape[0] and x+newim.shape[1] < back.shape[1]:\n",
        "                        break\n",
        "                gtt = np.zeros_like(groundtruth)\n",
        "                gtt[y:y+newim.shape[0], x:x+newgt.shape[1]] = newgt\n",
        "                n2and1 = len(np.where((gtt * finalgt) > 0)[0])\n",
        "                n1 = len(np.where(gtt > 0)[0])\n",
        "                n2 = len(np.where(gtt > 0)[0])\n",
        "                if n2and1 < min(n1, n2) * 0.5:\n",
        "                    break\n",
        "        xywh.append((x, y, newgt.shape[1], newgt.shape[0]))\n",
        "        imm = np.zeros_like(groundtruth)\n",
        "        imm[y:y+newim.shape[0], x:x+newim.shape[1]] = newim\n",
        "\n",
        "        finalgt[gtt!=0] = 1 + order\n",
        "        finalim = finalim * (1-gtt) + imm * (gtt)\n",
        "        \n",
        "    return finalim, finalgt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tw3zPMK7NNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadimage(path, mode, i):\n",
        "    middle = \"/groundtruth/\" if mode == \"gt\" else \"/input/\"\n",
        "    prefix = \".png\" if mode == \"gt\" else \".jpg\"\n",
        "    filename = path + middle + mode + str(i).zfill(6) + prefix\n",
        "    # print(filename)\n",
        "    im = cv.imread(filename)\n",
        "    im = cv.cvtColor(im, cv.COLOR_BGR2RGB)\n",
        "    return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGXyo7TX7RKd",
        "colab_type": "code",
        "outputId": "5be1502e-74ce-41a3-af28-9539d112320e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import torch \n",
        "\n",
        "n_frames = 3000\n",
        "max_person = 3\n",
        "\n",
        "targets = [None] * n_frames\n",
        "\n",
        "for i in range(n_frames):\n",
        "    if i % 100 == 0:\n",
        "        print(i)\n",
        "    random.seed(i+1201)\n",
        "    n_person = random.randint(2, max_person)\n",
        "    random.seed(i*72)\n",
        "    overlap = False if random.uniform(0, 1) < 0.7 else True\n",
        "    overlap = False if n_person < 2 else overlap\n",
        "    random.seed(i)\n",
        "    f = i // (n_frames // 4)\n",
        "    f = list(files.keys())[f]\n",
        "    background = files[f][\"background\"]\n",
        "    random.seed(i + 192)\n",
        "    background = background[random.randint(0, len(background)-1)]\n",
        "    random.seed(i + 212)\n",
        "    background = random.randint(background[0], background[1] - 1)\n",
        "    background = loadimage(f, 'in', background)\n",
        "    foreground = files[f][\"foreground\"]\n",
        "\n",
        "    used = []\n",
        "    prs = []\n",
        "    gts = []\n",
        "    for j in range(0, n_person):\n",
        "        seedj = 0\n",
        "        while True:\n",
        "            seedj += 1\n",
        "            random.seed(seedj + 1982)\n",
        "            foreGroup = random.randint(0, len(foreground) - 1)\n",
        "            if foreGroup not in used:\n",
        "                break\n",
        "        used.append(foreGroup)\n",
        "        random.seed(i + 2763)\n",
        "        fore = random.randint(0, len(foreground[foreGroup]) - 1)\n",
        "        fore = foreground[foreGroup][fore]\n",
        "        person = loadimage(f, 'in', fore)\n",
        "        ground = loadimage(f, 'gt', fore)\n",
        "        ground[ground<160] = 0\n",
        "        retval, labels = cv.connectedComponents(ground[:,:,0])\n",
        "        \n",
        "        for k in range(0, retval):\n",
        "            im = np.zeros((labels.shape[0], labels.shape[1], 3))\n",
        "            mask = np.zeros_like(ground)\n",
        "            mask[ground>200] = 1\n",
        "            im[labels == k, :] = 1\n",
        "            im[labels != k, :] = 0\n",
        "            im[im>0] = ground[im>0]\n",
        "            im = im * mask\n",
        "            if np.max(im) > 0:\n",
        "                prs.append(person)\n",
        "                gts.append(im)\n",
        "        \n",
        "    a = aa(0, len(prs))\n",
        "    random.seed(i)\n",
        "    random.shuffle(a)\n",
        "    a = a[:n_person]\n",
        "    prs = [prs[i] for i in a]\n",
        "    gts = [gts[i] for i in a]\n",
        "    \n",
        "    f, g = syn(prs, gts, background, overlap, i)\n",
        "    f = cv.cvtColor(np.uint8(f), cv.COLOR_RGB2BGR)\n",
        "    boxes = []\n",
        "    obj_ids = np.unique(g)[1:]\n",
        "    for idx in obj_ids:\n",
        "        pos = np.where(g==idx)\n",
        "        xmin = np.min(pos[1])\n",
        "        xmax = np.max(pos[1])\n",
        "        ymin = np.min(pos[0])\n",
        "        ymax = np.max(pos[0])\n",
        "        boxes.append([xmin, ymin, xmax, ymax])\n",
        "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "    labels = torch.ones((len(boxes),), dtype=torch.int64)\n",
        "    image_id = torch.tensor([i])\n",
        "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "    iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
        "    target = {}\n",
        "    target[\"boxes\"] = boxes\n",
        "    target[\"labels\"] = labels\n",
        "    target[\"image_id\"] = image_id\n",
        "    target[\"area\"] = area\n",
        "    target[\"iscrowd\"] = iscrowd\n",
        "    targets[i] = target\n",
        "\n",
        "    cv.imwrite(\"/content/dataset/gt/\" + str(i).zfill(6) + '.png', g)\n",
        "    cv.imwrite(\"/content/dataset/in/\" + str(i).zfill(6) + '.jpg', f)\n",
        "    cv.imwrite(\"/content/dataset/bk/\" + str(i).zfill(6) + '.jpg', background)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw5XdcZ87gry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(19872)\n",
        "idx = list(range(0, n_frames))\n",
        "random.shuffle(idx)\n",
        "trainset = idx[:n_frames//6*4]\n",
        "valset = idx[n_frames//6*4:n_frames//6*5]\n",
        "testset = idx[n_frames//6*5:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNZ188tZ8ivY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
        "from torchvision.models.detection.generalized_rcnn import GeneralizedRCNN\n",
        "\n",
        "from collections import OrderedDict\n",
        "from torch import nn\n",
        "import warnings\n",
        "from torch.jit.annotations import Tuple, List, Dict, Optional\n",
        "from torch import Tensor\n",
        "from copy import deepcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17jWN1h18mar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NetA = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True) \n",
        "NetA.transform = GeneralizedRCNNTransform(min_size=400,\n",
        "                                     max_size=800,\n",
        "                                     image_mean = [0.485, 0.456, 0.406],\n",
        "                                     image_std = [0.229, 0.224, 0.225])\n",
        "\n",
        "for p in NetA.parameters():\n",
        "    p.requires_grad = False\n",
        "NetA.roi_heads.box_predictor.cls_score = nn.Linear(in_features=1024, out_features=2, bias=True)\n",
        "NetA.roi_heads.box_predictor.bbox_pred = nn.Linear(in_features=1024, out_features=8, bias=True)\n",
        "for name, param in NetA.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z05FWS7svrfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IOU(boxA, boxB):\n",
        "    l = max(boxA[0], boxB[0])\n",
        "    r = min(boxA[2], boxB[2])\n",
        "    t = max(boxA[1], boxB[1])\n",
        "    b = max(boxA[3], boxB[3])\n",
        "\n",
        "    intersection = max(r-l, 0) * max(b-t, 0)\n",
        "    union = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]) + (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]) - intersection\n",
        "    return intersection / union\n",
        "\n",
        "def SCORE(gts, dets):\n",
        "    if len(gts) == 0:\n",
        "        return 0, len(dets), 0\n",
        "    if len(dets) == 0:\n",
        "        return 0, 0, len(gts)\n",
        "    scores = np.zeros((len(dets), len(gts)))\n",
        "    mask = np.ones_like(scores)\n",
        "    for i, gt in enumerate(gts):\n",
        "        for j, det in enumerate(dets):\n",
        "            scores[j, i] = IOU(gt, det)\n",
        "    TP, FP, FN = 0, 0, 0\n",
        "    t = []\n",
        "    while np.max(mask*scores) > 0:\n",
        "        loc = np.argmax(mask * scores)\n",
        "        val = np.max(mask * scores)\n",
        "        mask[loc//mask.shape[1], :] = 0\n",
        "        mask[:, loc%mask.shape[1]] = 0\n",
        "        # print(mask)\n",
        "        if val > 0.5:\n",
        "            TP += 1\n",
        "    FN = len(gts) - TP\n",
        "    FP = len(dets) - TP\n",
        "    return TP, FP, FN\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pjjGjqU8pRk",
        "colab_type": "code",
        "outputId": "350ad3c8-e77a-4c46-93bb-bd8c1a14e7de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "n_epochs = 20\n",
        "batch_size = 10\n",
        "def imread(path, num):\n",
        "    im = Image.open(path + str(num).zfill(6) + \".jpg\")\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    im = transform(im)\n",
        "    return im.cuda()\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "params = [p for p in NetA.parameters() if p.requires_grad]\n",
        "\n",
        "optimizer = optim.Adam(params, lr=0.001)\n",
        "\n",
        "\n",
        "NetA.cuda()\n",
        "min_loss = np.inf\n",
        "history = {'train_loss': [],\n",
        "           'val_acc': []}\n",
        "best = 0\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = []\n",
        "    NetA.train()\n",
        "    for i in range(0, len(trainset), batch_size):\n",
        "        print(\"\\r Epoch %d, training [%d / %d]\" % (epoch+1, i//batch_size+1, int(len(trainset)/batch_size)), end='')\n",
        "        optimizer.zero_grad()\n",
        "        ids = trainset[i:i+batch_size]\n",
        "        sample = [imread(\"/content/dataset/in/\", num) for num in ids]\n",
        "        target = [{k: v.cuda() for k, v in targets[num].items()} for num in ids]\n",
        "        loss_dict = NetA(sample, target)\n",
        "        running_loss = sum([loss for loss in loss_dict.values()])\n",
        "        running_loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(running_loss.item())\n",
        "    NetA.eval()\n",
        "    TP, FP, FN = 0, 0, 0\n",
        "    print(\"\")\n",
        "    for i in range(0, len(valset), batch_size):\n",
        "        print(\"\\r Epoch %d, validation [%d / %d]\" % (epoch+1, i//batch_size+1, int(len(valset)/batch_size)), end='')\n",
        "        ids = valset[i:i+batch_size]\n",
        "        sample = [imread(\"/content/dataset/in/\", num) for num in ids]\n",
        "        back = []\n",
        "        for num in ids:\n",
        "            random.seed(num)\n",
        "            p = random.uniform(0, 1)\n",
        "            if p < 0.25:\n",
        "                back.append(imread(\"/content/dataset/bk/\", num))\n",
        "            elif p < 0.5:\n",
        "                random.seed(num)\n",
        "                pp = (n_frames // 4)\n",
        "                x = random.randint(pp * (num//pp), pp * (num//pp + 1)-1)\n",
        "                back.append(imread(\"/content/dataset/bk/\", x))\n",
        "            elif p < 0.75:\n",
        "                back.append(imread(\"/content/dataset/in/\", num))\n",
        "            else: \n",
        "                random.seed(num)\n",
        "                pp = (n_frames // 4)\n",
        "                x = random.randint(pp * (num//pp), pp * (num//pp + 1)-1)\n",
        "                back.append(imread(\"/content/dataset/in/\", x))\n",
        "        target = [{k: v.numpy() for k, v in targets[num].items()} for num in ids]\n",
        "        gts = []\n",
        "        for t in target:\n",
        "            boxes = t[\"boxes\"]\n",
        "            gt = [box for box in boxes]\n",
        "            gts.append(gt)\n",
        "        detections = NetA(sample)\n",
        "        results = []\n",
        "        for detection in detections:\n",
        "            result = []\n",
        "            scores = detection[\"scores\"].detach().cpu()\n",
        "            boxes = detection[\"boxes\"].detach().cpu()\n",
        "            for j, score in enumerate(scores):\n",
        "                if score > 0.5:\n",
        "                    result.append(boxes[j].numpy())\n",
        "            results.append(result)\n",
        "\n",
        "        for j, gt in enumerate(gts):\n",
        "            tp, fp, fn = SCORE(gt, results[j])\n",
        "            TP += tp\n",
        "            FP += fp\n",
        "            FN += fn\n",
        "    print(\"\")\n",
        "    if TP == 0:\n",
        "        b = 0\n",
        "    else:\n",
        "        Recall = TP / (TP + FN)\n",
        "        Precision = TP / (TP + FP)\n",
        "        b = (2 * Precision * Recall) / (Precision + Recall)\n",
        "    a = np.mean(np.array(train_loss))\n",
        "    print(\"Epochs: %d, train loss=%f, val acc= %f\" % (epoch+1, a, b))\n",
        "    if b > best:\n",
        "        best = b\n",
        "        print(\"==> best model (acc = {:0.6f}), saving model...\".format(b))\n",
        "        best_weights = deepcopy(NetA.state_dict())\n",
        "        torch.save(best_weights, \"/content/drive/My Drive/889PR/bestA.pth\")\n",
        "    \n",
        "    history[\"train_loss\"].append(a)\n",
        "    history[\"val_acc\"].append(b)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r Epoch 1, training [1 / 200]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch 1, training [200 / 200]\n",
            " Epoch 1, validation [50 / 50]\n",
            "Epochs: 1, train loss=0.196437, val acc= 0.843430\n",
            "==> best model (acc = 0.843430), saving model...\n",
            " Epoch 2, training [200 / 200]\n",
            " Epoch 2, validation [50 / 50]\n",
            "Epochs: 2, train loss=0.152354, val acc= 0.842675\n",
            " Epoch 3, training [200 / 200]\n",
            " Epoch 3, validation [50 / 50]\n",
            "Epochs: 3, train loss=0.145574, val acc= 0.844086\n",
            "==> best model (acc = 0.844086), saving model...\n",
            " Epoch 4, training [200 / 200]\n",
            " Epoch 4, validation [50 / 50]\n",
            "Epochs: 4, train loss=0.142537, val acc= 0.846943\n",
            "==> best model (acc = 0.846943), saving model...\n",
            " Epoch 5, training [200 / 200]\n",
            " Epoch 5, validation [50 / 50]\n",
            "Epochs: 5, train loss=0.141263, val acc= 0.842145\n",
            " Epoch 6, training [200 / 200]\n",
            " Epoch 6, validation [50 / 50]\n",
            "Epochs: 6, train loss=0.140077, val acc= 0.841052\n",
            " Epoch 7, training [200 / 200]\n",
            " Epoch 7, validation [50 / 50]\n",
            "Epochs: 7, train loss=0.138087, val acc= 0.851175\n",
            "==> best model (acc = 0.851175), saving model...\n",
            " Epoch 8, training [200 / 200]\n",
            " Epoch 8, validation [50 / 50]\n",
            "Epochs: 8, train loss=0.137892, val acc= 0.853631\n",
            "==> best model (acc = 0.853631), saving model...\n",
            " Epoch 9, training [200 / 200]\n",
            " Epoch 9, validation [50 / 50]\n",
            "Epochs: 9, train loss=0.136096, val acc= 0.853541\n",
            " Epoch 10, training [200 / 200]\n",
            " Epoch 10, validation [50 / 50]\n",
            "Epochs: 10, train loss=0.135832, val acc= 0.852799\n",
            " Epoch 11, training [125 / 200]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZOkM_jeFXwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NetA = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True) \n",
        "# NetA.transform = GeneralizedRCNNTransform(min_size=400,\n",
        "#                                      max_size=800,\n",
        "#                                      image_mean = [0.485, 0.456, 0.406],\n",
        "#                                      image_std = [0.229, 0.224, 0.225])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv3EpTYwGfg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# im = Image.open(\"/content/1.jpg\")\n",
        "# im = T.Compose([T.ToTensor()])(im)\n",
        "# NetA.cuda()\n",
        "# NetA.eval()\n",
        "\n",
        "# detections = NetA([im.cuda()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbw0Gq5Nznku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(detections)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reORXIxFzsXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# results = []\n",
        "# for detection in detections:\n",
        "#     result = []\n",
        "#     scores = detection[\"scores\"].detach().cpu()\n",
        "#     boxes = detection[\"boxes\"].detach().cpu()\n",
        "#     for i, score in enumerate(scores):\n",
        "#         if score > 0.5:\n",
        "#             result.append(boxes[i].numpy())\n",
        "#     results.append(result)\n",
        "# print(results)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s9p0j9lz7TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i = 0\n",
        "# batch_size = 10\n",
        "# ids = valset[i:i+batch_size]\n",
        "# target = [{k: v for k, v in targets[num].items()} for num in ids]\n",
        "\n",
        "# gts = []\n",
        "# for t in target:\n",
        "#     boxes = t[\"boxes\"].numpy()\n",
        "#     gt = [box for box in boxes]\n",
        "#     gts.append(gt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYoJGhkfDaBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_z13RErclex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}